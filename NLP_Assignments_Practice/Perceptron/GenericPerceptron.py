#  
#Name : Aditya Ramachandra Desai
#USC ID : 5246-4961-15
#Script : Peceptron General Class. This class has all the required functionalities required to activate
#         both Standard Perceptron and Average Perceptron

import os
import sys
import io
import collections
import json
import ast
from random import shuffle
from functools import lru_cache
ITERATION = '20'
AVG_ITERATION = '30'

class GenericPerceptron:
    def __init__(self):
        self.labeldFiles = []
        self.weights = collections.defaultdict(int)
        self.avgWeights = collections.defaultdict(int)
        self.bias = 0
        self.beta = 0
        self.count = 1
        self.result=""
    def labelData(self, inputPath):
        for root, dirs, files in os.walk(inputPath):
            label = ""
            for name in files:
                if name.startswith("."):
                    continue
                if name.endswith('spam.txt'):
                    label = 1
                elif name.endswith('ham.txt'):
                    label = -1
                yield label, os.path.join(root, name)
    def shuffle(self):
        shuffle(self.labeldFiles)
    def printDetails(self):
        for key, value in self.weights.items():
            print(key + " : " + str(value))
    
    #
    # The following function calculates the Alpha parameter mentioned in the algorithm for standard perceptron
    #
    def calculateAlpha(self, vectorInput):
        b = self.bias;
        for key, value in vectorInput.items():
            b += self.weights.get(key,0) * value
        return b;
    #
    # The following function calculates the Alpha parameter mentioned in the algorithm for average perceptron
    #
    def calculateAvgAlpha(self, vectorInput):
        b = self.beta;
        for key, value in vectorInput.items():
            b += self.avgWeights.get(key,0) * value
        return b;
    
    # The following function returns the x parameter or the input vector mentioend in the algorithm for 
    # both standard and average perceptron
    # Here lru_cache is being set, so that there are timeout happening on Vocareum. 
    # With profiling, this function was taking more time and I made an trial-and-error menthod to set this value of 2048 * 2048
    @lru_cache(maxsize=2048*2048)
    def returnVector(self,eachFile):
        vectorInput = collections.defaultdict(int)
        with io.open(eachFile, "r", encoding="latin1") as sFile:
            for textLine in sFile: 
                textLine = textLine.split(" ")
                for word in textLine:
                    word = word.strip("\n")
                    word = word.strip("\r")
                    vectorInput[word] += 1
        return vectorInput
    # The following function is only for Standard Perceptron
    # The following function will calculate the labels "<SPAM/HAM Full-directory path for a file>"
    # For each iteration, the labels are shuffled.      
    def processLables(self):
        for i in range(int(ITERATION)):
            self.shuffle()
            for label, eachFile in self.labeldFiles:
                if label == "":
                    raise Exception("No Label found for " + eachFile)
                else:
                    vectorInput = self.returnVector(eachFile)
                    alpha = self.calculateAlpha(vectorInput)
                    if (alpha * label <= 0):
                       self.updateWeightsBias(vectorInput,label)
    # The following function is to read the model generated by the learning of training data
    # by the standard and average perceptron
    # The model is later stored in the memory.   
    def readModel(self):
        with io.open("per_model.txt","r") as data_file:
            data = dict()    
            data = json.load(data_file)
            self.weights = ast.literal_eval(data['WEIGHT'])
            self.avgWeights = ast.literal_eval(data['AVG_WEIGHT'])
            self.bias = data['BIAS']
            self.count = data['COUNT']
            self.beta = data['BETA']
            #Check if model is correctly imported
            #print("Imported Data from Model")
            #print("Length of Imported Weights is "+ str(len(self.weights)))
            #print("Length of Imported Avg Weights is "+ str(len(self.avgWeights)))
            #print("BIAS "+str(data['BIAS']))
            #print("BETA "+str(data['BETA']))
            #print("COUNT "+str(data['COUNT']))
    # The following function is only for Standard Perceptron and Average Perceptron
    # The following function will classify the files as Spam or Ham based on the value of alpha calculated
    #
    def classifyData(self):
            newLabel=""
            for label, eachFile in self.labeldFiles:
                    vectorInput = collections.defaultdict(int)
                    with io.open(eachFile, "r", encoding="latin1") as sFile:
                        for textLine in sFile: 
                            textLine = textLine.split(" ")
                            for word in textLine:
                                word = word.strip("\n")
                                word = word.strip("\r")
                                vectorInput[word] += 1
                    if(self.count==1 and self.beta==0):
                        alpha = self.calculateAlpha(vectorInput)
                        if (alpha < 0):
                            newLabel="ham"
                        else:
                            newLabel="spam"
                    elif(self.count>1 and self.beta!=0):
                        avgAlpha = self.calculateAvgAlpha(vectorInput)
                        if (avgAlpha < 0):
                            newLabel="ham"
                            #print("Ham file is " + eachFile)
                        else:
                            newLabel="spam"     
                            #print("Spam file is " + eachFile)
                    self.result+=newLabel+" "+str(eachFile)+"\n"
    # The following function is only for Standard Perceptron
    # If weight and bias needs to be updated the following function will be called
    # 
    def updateWeightsBias(self, vectorInput,label):
        self.bias += label
        for key, val in vectorInput.items():
            self.weights[key] += val * label  
    # The following function is only for Average Perceptron
    # The following function will be called to update the weighed average vector, (U) as mentioned
    # in the algorithm
    def updateAvgModel(self):
        oneOverC = float(1/self.count)
        for key1,value2 in self.avgWeights.items():
            self.avgWeights[key1] = self.weights[key1] - float(oneOverC * value2)
        self.beta = self.bias - float(oneOverC * self.beta)
    # The following function is only for Standard and Average Perceptron
    # The following function will write the model to the file 
    #    
    def writeModel(self):
        s1 = json.dumps(self.weights, indent=5, sort_keys=True) 
        s2 = json.dumps(self.avgWeights, indent=5, sort_keys=True)
        sDict = dict()
        sDict['BIAS'] = self.bias
        sDict['WEIGHT'] = s1
        sDict['AVG_WEIGHT']=s2
        sDict['BETA']=self.beta
        sDict['COUNT']=self.count
        sWrite = json.dumps(sDict, indent=4, sort_keys=True)   
        with open("per_model.txt", "w") as text_file:
            text_file.write(sWrite)
    # The following function is only for Standard  and Average Perceptron
    # The following function will write the results of the respective classification into a file
    # Format will be <LABEL DIRECTORY-PATH>
    def writeResult(self,fileName):
        with io.open(fileName, 'w') as output:
            output.write(self.result)
    # The following function is only for Average Perceptron
    # The following function will calculate the labels "<SPAM/HAM Full-directory path for a file>"
    # For each iteration, the labels are shuffled.
    def averageProcessLabels(self):
        for i in range(int(AVG_ITERATION)):
            self.shuffle()
            for label, eachFile in self.labeldFiles:
                if label == "":
                    raise Exception("Avg Process Label - No Label found for " + eachFile)
                else:
                    vectorInput = self.returnVector(eachFile)
                    alpha = self.calculateAlpha(vectorInput)
                    if (alpha * label <= 0):
                       self.updateAvgWeightsBeta(vectorInput,label)
                    self.count+=1
    # The following function is only for Average Perceptron
    # If weight,beta and bias needs to be updated the following function will be called
    # 
    def updateAvgWeightsBeta(self,vectorInput,label):
        self.bias += label
        for key, val in vectorInput.items():
            self.weights[key] += val * label 
        self.beta += label * self.count
        for key, val in vectorInput.items():
            self.avgWeights[key] += val * label * self.count
    # The following function is only for Standard and Average Perceptron
    # The following function will calculate F1 Score , precision and confusion matrix
    # 
    def evaluate(self,fileName):
            predictResults = []
            accuracy = 0.0
            precisionHam = 0.0
            precisionSpam = 0.0
            recallHam = 0.0
            recallSpam = 0.0
            hamInHam = 0.0
            spamInHam = 0.0
            spamInSpam = 0.0 
            hamInSpam = 0.0
            FScoreHam = 0.0
            FScoreSpam = 0.0
         
            with io.open(fileName, "r", encoding='utf-8') as rFile:
                for line in rFile:
                    whiteSpaceIndex = line.find(" ")
                    predictLabel = line[0:whiteSpaceIndex]
                    filePath = line[whiteSpaceIndex + 1:]
                    fileName = filePath[filePath.rfind("/") + 1:]
                    if "ham" in fileName:
                        actualLabel = "ham"
                    else:
                        actualLabel = "spam"
                    predictResults = predictResults + [(predictLabel, actualLabel)]
            truthTable = [[0, 0], [0, 0]]
            for result in predictResults:
                if(result[0] == result[1] == "ham"):
                    truthTable[0][0] = truthTable[0][0] + 1
                elif(result[0] == result[1] == "spam"):
                    truthTable[1][1] = truthTable[1][1] + 1
                elif(result[0] == "ham" and result[1] == "spam"):
                    truthTable[1][0] = truthTable[1][0] + 1
                else:
                    truthTable[0][1] = truthTable[0][1] + 1

            print(truthTable)
            precisionHam = truthTable[0][0] / (truthTable[0][0] + truthTable[1][0])
            recallHam = truthTable[0][0] / (truthTable[0][0] + truthTable[0][1])
            fscoreHam = 2 * precisionHam * recallHam / (precisionHam + recallHam)
            print("HAM Precision:{0},Recall:{1},F1Score:{2}".format(precisionHam, recallHam, fscoreHam))
            precisionSpam = truthTable[1][1] / (truthTable[1][1] + truthTable[0][1])
            recallSpam = truthTable[1][1] / (truthTable[1][1] + truthTable[1][0])
            fscoreSpam = 2 * precisionSpam * recallSpam / (precisionSpam + recallSpam)
            print("SPAM Precision:{0},Recall:{1},F1Score:{2}".format(precisionSpam, recallSpam, fscoreSpam))
